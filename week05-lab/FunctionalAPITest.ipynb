{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all neural network models are simply sequential. Some may have complex topologies. Some may have multiple inputs and/or multiple outputs. For example, a Wide & Deep neural network (see paper) connects all or part of the inputs directly to the output layer.\n",
    "Letâ€™s build such a neural network to tackle the California housing problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 30)           270         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 30)           930         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4492 - val_loss: 0.4691\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4465 - val_loss: 0.4643\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4435 - val_loss: 0.4630\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4411 - val_loss: 0.4605\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4395 - val_loss: 0.4579\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4363 - val_loss: 0.4570\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4338 - val_loss: 0.4529\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4313 - val_loss: 0.4513\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4291 - val_loss: 0.4496\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4274 - val_loss: 0.4477\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4250 - val_loss: 0.4462\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4232 - val_loss: 0.4445\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4215 - val_loss: 0.4427\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4196 - val_loss: 0.4404\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4177 - val_loss: 0.4407\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.4378\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4143 - val_loss: 0.4378\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4130 - val_loss: 0.4349\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4113 - val_loss: 0.4337\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4099 - val_loss: 0.4328\n",
      "162/162 [==============================] - 0s 762us/step - loss: 0.4192\n",
      "1/1 [==============================] - 0s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you want to send different subsets of input features through the wide or deep paths? We will send 5 features (features 0 to 4), and 6 through the deep path (features 2 to 7). Note that 3 features will go through both (features 2, 3 and 4).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.0909 - val_loss: 0.8706\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7442 - val_loss: 0.6824\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6510 - val_loss: 0.6258\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5936 - val_loss: 0.5928\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5703 - val_loss: 0.5698\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5447 - val_loss: 0.5554\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5298 - val_loss: 0.5427\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5180 - val_loss: 0.5340\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5097 - val_loss: 0.5267\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5026 - val_loss: 0.5208\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4958 - val_loss: 0.5148\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4905 - val_loss: 0.5098\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4853 - val_loss: 0.5051\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4812 - val_loss: 0.5009\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4770 - val_loss: 0.4979\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4736 - val_loss: 0.4936\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4698 - val_loss: 0.4909\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4677 - val_loss: 0.4871\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4641 - val_loss: 0.4840\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4614 - val_loss: 0.4818\n",
      "162/162 [==============================] - 0s 801us/step - loss: 0.4740\n",
      "1/1 [==============================] - 0s 55ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an auxiliary output for regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 2s 132us/sample - loss: 2.1388 - main_output_loss: 1.9341 - aux_output_loss: 3.9759 - val_loss: 1.0634 - val_main_output_loss: 0.8326 - val_aux_output_loss: 3.1391\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 86us/sample - loss: 0.9184 - main_output_loss: 0.7344 - aux_output_loss: 2.5738 - val_loss: 0.8119 - val_main_output_loss: 0.6546 - val_aux_output_loss: 2.2267\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 92us/sample - loss: 0.7613 - main_output_loss: 0.6333 - aux_output_loss: 1.9130 - val_loss: 0.7349 - val_main_output_loss: 0.6129 - val_aux_output_loss: 1.8316\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.7012 - main_output_loss: 0.5986 - aux_output_loss: 1.6236 - val_loss: 0.6949 - val_main_output_loss: 0.5897 - val_aux_output_loss: 1.6402\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.6660 - main_output_loss: 0.5758 - aux_output_loss: 1.4785 - val_loss: 0.6664 - val_main_output_loss: 0.5723 - val_aux_output_loss: 1.5124\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.6406 - main_output_loss: 0.5576 - aux_output_loss: 1.3874 - val_loss: 0.6452 - val_main_output_loss: 0.5590 - val_aux_output_loss: 1.4204\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.6205 - main_output_loss: 0.5428 - aux_output_loss: 1.3201 - val_loss: 0.6268 - val_main_output_loss: 0.5463 - val_aux_output_loss: 1.3504\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.6042 - main_output_loss: 0.5303 - aux_output_loss: 1.2679 - val_loss: 0.6125 - val_main_output_loss: 0.5369 - val_aux_output_loss: 1.2920\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.5905 - main_output_loss: 0.5204 - aux_output_loss: 1.2231 - val_loss: 0.6013 - val_main_output_loss: 0.5299 - val_aux_output_loss: 1.2435\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.5797 - main_output_loss: 0.5121 - aux_output_loss: 1.1874 - val_loss: 0.5921 - val_main_output_loss: 0.5252 - val_aux_output_loss: 1.1925\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.5702 - main_output_loss: 0.5055 - aux_output_loss: 1.1518 - val_loss: 0.5814 - val_main_output_loss: 0.5170 - val_aux_output_loss: 1.1609\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.5620 - main_output_loss: 0.4995 - aux_output_loss: 1.1239 - val_loss: 0.5749 - val_main_output_loss: 0.5132 - val_aux_output_loss: 1.1288\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 0.5544 - main_output_loss: 0.4939 - aux_output_loss: 1.0972 - val_loss: 0.5676 - val_main_output_loss: 0.5079 - val_aux_output_loss: 1.1036\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 127us/sample - loss: 0.5484 - main_output_loss: 0.4900 - aux_output_loss: 1.0732 - val_loss: 0.5626 - val_main_output_loss: 0.5049 - val_aux_output_loss: 1.0811\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 95us/sample - loss: 0.5426 - main_output_loss: 0.4859 - aux_output_loss: 1.0518 - val_loss: 0.5583 - val_main_output_loss: 0.5028 - val_aux_output_loss: 1.0575\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 101us/sample - loss: 0.5377 - main_output_loss: 0.4826 - aux_output_loss: 1.0328 - val_loss: 0.5534 - val_main_output_loss: 0.4994 - val_aux_output_loss: 1.0380\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 98us/sample - loss: 0.5332 - main_output_loss: 0.4797 - aux_output_loss: 1.0139 - val_loss: 0.5485 - val_main_output_loss: 0.4960 - val_aux_output_loss: 1.0205\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 71us/sample - loss: 0.5289 - main_output_loss: 0.4772 - aux_output_loss: 0.9968 - val_loss: 0.5446 - val_main_output_loss: 0.4936 - val_aux_output_loss: 1.0025\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 95us/sample - loss: 0.5251 - main_output_loss: 0.4744 - aux_output_loss: 0.9803 - val_loss: 0.5421 - val_main_output_loss: 0.4927 - val_aux_output_loss: 0.9861\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 113us/sample - loss: 0.5214 - main_output_loss: 0.4722 - aux_output_loss: 0.9645 - val_loss: 0.5385 - val_main_output_loss: 0.4901 - val_aux_output_loss: 0.9733\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 29us/sample - loss: 0.5300 - main_output_loss: 0.4847 - aux_output_loss: 0.9471\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
