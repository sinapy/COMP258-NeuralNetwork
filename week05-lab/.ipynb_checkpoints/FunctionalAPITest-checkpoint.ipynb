{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all neural network models are simply sequential. Some may have complex topologies. Some may have multiple inputs and/or multiple outputs. For example, a Wide & Deep neural network (see paper) connects all or part of the inputs directly to the output layer.\n",
    "Letâ€™s build such a neural network to tackle the California housing problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 30)           270         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 30)           930         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 38)           0           input_2[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            39          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 2s 151us/sample - loss: 0.4434 - val_loss: 0.4621\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 2s 151us/sample - loss: 0.4404 - val_loss: 0.4576\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 97us/sample - loss: 0.4379 - val_loss: 0.4553\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 113us/sample - loss: 0.4351 - val_loss: 0.4536\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 2s 152us/sample - loss: 0.4329 - val_loss: 0.4505\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 113us/sample - loss: 0.4305 - val_loss: 0.4483\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 94us/sample - loss: 0.4283 - val_loss: 0.4469\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.4263 - val_loss: 0.4454\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 2s 139us/sample - loss: 0.4241 - val_loss: 0.4443\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 125us/sample - loss: 0.4224 - val_loss: 0.4428\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 72us/sample - loss: 0.4206 - val_loss: 0.4402\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.4189 - val_loss: 0.4387\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.4167 - val_loss: 0.4376\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.4155 - val_loss: 0.4359\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.4136 - val_loss: 0.4346\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4118 - val_loss: 0.4331\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4103 - val_loss: 0.4316\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4086 - val_loss: 0.4305\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4073 - val_loss: 0.4288\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4056 - val_loss: 0.4299\n",
      "5160/5160 [==============================] - 0s 24us/sample - loss: 0.4165\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you want to send different subsets of input features through the wide or deep paths? We will send 5 features (features 0 to 4), and 6 through the deep path (features 2 to 7). Note that 3 features will go through both (features 2, 3 and 4).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 2s 145us/sample - loss: 1.8306 - val_loss: 0.8003\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 2s 152us/sample - loss: 0.7165 - val_loss: 0.6435\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 2s 152us/sample - loss: 0.6232 - val_loss: 0.6048\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 73us/sample - loss: 0.5902 - val_loss: 0.5829\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.5682 - val_loss: 0.5661\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.5510 - val_loss: 0.5540\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 2s 148us/sample - loss: 0.5372 - val_loss: 0.5433\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 2s 150us/sample - loss: 0.5261 - val_loss: 0.5356\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 2s 155us/sample - loss: 0.5169 - val_loss: 0.5301\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 91us/sample - loss: 0.5100 - val_loss: 0.5251\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 68us/sample - loss: 0.5036 - val_loss: 0.5177\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 2s 149us/sample - loss: 0.4983 - val_loss: 0.5145\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 90us/sample - loss: 0.4930 - val_loss: 0.5096\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 2s 144us/sample - loss: 0.4894 - val_loss: 0.5073\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 93us/sample - loss: 0.4854 - val_loss: 0.5052\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 2s 143us/sample - loss: 0.4822 - val_loss: 0.5019\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 111us/sample - loss: 0.4791 - val_loss: 0.4977\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 128us/sample - loss: 0.4762 - val_loss: 0.4955\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 99us/sample - loss: 0.4736 - val_loss: 0.4950\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.4711 - val_loss: 0.4912\n",
      "5160/5160 [==============================] - 0s 25us/sample - loss: 0.4881\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an auxiliary output for regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 2s 132us/sample - loss: 2.1388 - main_output_loss: 1.9341 - aux_output_loss: 3.9759 - val_loss: 1.0634 - val_main_output_loss: 0.8326 - val_aux_output_loss: 3.1391\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 86us/sample - loss: 0.9184 - main_output_loss: 0.7344 - aux_output_loss: 2.5738 - val_loss: 0.8119 - val_main_output_loss: 0.6546 - val_aux_output_loss: 2.2267\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 92us/sample - loss: 0.7613 - main_output_loss: 0.6333 - aux_output_loss: 1.9130 - val_loss: 0.7349 - val_main_output_loss: 0.6129 - val_aux_output_loss: 1.8316\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.7012 - main_output_loss: 0.5986 - aux_output_loss: 1.6236 - val_loss: 0.6949 - val_main_output_loss: 0.5897 - val_aux_output_loss: 1.6402\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.6660 - main_output_loss: 0.5758 - aux_output_loss: 1.4785 - val_loss: 0.6664 - val_main_output_loss: 0.5723 - val_aux_output_loss: 1.5124\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.6406 - main_output_loss: 0.5576 - aux_output_loss: 1.3874 - val_loss: 0.6452 - val_main_output_loss: 0.5590 - val_aux_output_loss: 1.4204\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.6205 - main_output_loss: 0.5428 - aux_output_loss: 1.3201 - val_loss: 0.6268 - val_main_output_loss: 0.5463 - val_aux_output_loss: 1.3504\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.6042 - main_output_loss: 0.5303 - aux_output_loss: 1.2679 - val_loss: 0.6125 - val_main_output_loss: 0.5369 - val_aux_output_loss: 1.2920\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.5905 - main_output_loss: 0.5204 - aux_output_loss: 1.2231 - val_loss: 0.6013 - val_main_output_loss: 0.5299 - val_aux_output_loss: 1.2435\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.5797 - main_output_loss: 0.5121 - aux_output_loss: 1.1874 - val_loss: 0.5921 - val_main_output_loss: 0.5252 - val_aux_output_loss: 1.1925\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.5702 - main_output_loss: 0.5055 - aux_output_loss: 1.1518 - val_loss: 0.5814 - val_main_output_loss: 0.5170 - val_aux_output_loss: 1.1609\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.5620 - main_output_loss: 0.4995 - aux_output_loss: 1.1239 - val_loss: 0.5749 - val_main_output_loss: 0.5132 - val_aux_output_loss: 1.1288\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 0.5544 - main_output_loss: 0.4939 - aux_output_loss: 1.0972 - val_loss: 0.5676 - val_main_output_loss: 0.5079 - val_aux_output_loss: 1.1036\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 127us/sample - loss: 0.5484 - main_output_loss: 0.4900 - aux_output_loss: 1.0732 - val_loss: 0.5626 - val_main_output_loss: 0.5049 - val_aux_output_loss: 1.0811\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 95us/sample - loss: 0.5426 - main_output_loss: 0.4859 - aux_output_loss: 1.0518 - val_loss: 0.5583 - val_main_output_loss: 0.5028 - val_aux_output_loss: 1.0575\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 101us/sample - loss: 0.5377 - main_output_loss: 0.4826 - aux_output_loss: 1.0328 - val_loss: 0.5534 - val_main_output_loss: 0.4994 - val_aux_output_loss: 1.0380\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 98us/sample - loss: 0.5332 - main_output_loss: 0.4797 - aux_output_loss: 1.0139 - val_loss: 0.5485 - val_main_output_loss: 0.4960 - val_aux_output_loss: 1.0205\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 71us/sample - loss: 0.5289 - main_output_loss: 0.4772 - aux_output_loss: 0.9968 - val_loss: 0.5446 - val_main_output_loss: 0.4936 - val_aux_output_loss: 1.0025\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 95us/sample - loss: 0.5251 - main_output_loss: 0.4744 - aux_output_loss: 0.9803 - val_loss: 0.5421 - val_main_output_loss: 0.4927 - val_aux_output_loss: 0.9861\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 113us/sample - loss: 0.5214 - main_output_loss: 0.4722 - aux_output_loss: 0.9645 - val_loss: 0.5385 - val_main_output_loss: 0.4901 - val_aux_output_loss: 0.9733\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 29us/sample - loss: 0.5300 - main_output_loss: 0.4847 - aux_output_loss: 0.9471\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
