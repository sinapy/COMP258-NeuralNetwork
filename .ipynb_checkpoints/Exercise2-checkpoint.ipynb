{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d6ad2476-c4de-4e35-9932-d8fe7efcf3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Miscellaneous functions\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1cc488b1-cbd6-4828-9551-a05b955cd15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Libraries\n",
    "# Standard library\n",
    "import random\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"The list ``sizes`` contains the number of neurons in the\n",
    "        respective layers of the network.  For example, if the list\n",
    "        was [2, 3, 1] then it would be a three-layer network, with the\n",
    "        first layer containing 2 neurons, the second layer 3 neurons,\n",
    "        and the third layer 1 neuron.  The biases and weights for the\n",
    "        network are initialized randomly, using a Gaussian\n",
    "        distribution with mean 0, and variance 1.  Note that the first\n",
    "        layer is assumed to be an input layer, and by convention we\n",
    "        won't set any biases for those neurons, since biases are only\n",
    "        ever used in computing the outputs from later layers.\"\"\"\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            test_data=None):\n",
    "        \"\"\"Train the neural network using mini-batch stochastic\n",
    "        gradient descent.  The ``training_data`` is a list of tuples\n",
    "        ``(x, y)`` representing the training inputs and the desired\n",
    "        outputs.  The other non-optional parameters are\n",
    "        self-explanatory.  If ``test_data`` is provided then the\n",
    "        network will be evaluated against the test data after each\n",
    "        epoch, and partial progress printed out.  This is useful for\n",
    "        tracking progress, but slows things down substantially.\"\"\"\n",
    "\n",
    "        training_data = list(training_data)\n",
    "        n = len(X)\n",
    "\n",
    "        if test_data:\n",
    "            test_data = list(test_data)\n",
    "            n_test = len(test_data)\n",
    "\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)\n",
    "            ]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            if test_data:\n",
    "                print(\"Epoch {} : {} / {}\".format(j,self.evaluate(test_data),n_test));\n",
    "            else:\n",
    "                print(\"Epoch {} complete\".format(j))\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        \"\"\"Update the network's weights and biases by applying\n",
    "        gradient descent using backpropagation to a single mini batch.\n",
    "        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n",
    "        is the learning rate.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.weights = [w-(eta/len(mini_batch))*nw\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * \\\n",
    "            sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        # Note that the variable l in the loop below is used a little\n",
    "        # differently to the notation in Chapter 2 of the book.  Here,\n",
    "        # l = 1 means the last layer of neurons, l = 2 is the\n",
    "        # second-last layer, and so on.  It's a renumbering of the\n",
    "        # scheme in the book, used here to take advantage of the fact\n",
    "        # that Python can use negative indices in lists.\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
    "                        for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
    "        \\partial a for the output activations.\"\"\"\n",
    "        return (output_activations-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee94c9-5b4a-4d22-bfa7-126aaa070726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1fa16b14-1bcd-4262-8ee5-c4994fec9a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 46, 'name': 'Hepatitis', 'repository_url': 'https://archive.ics.uci.edu/dataset/46/hepatitis', 'data_url': 'https://archive.ics.uci.edu/static/public/46/data.csv', 'abstract': 'From G.Gong: CMU; Mostly Boolean or numeric-valued attribute types; Includes cost data (donated by Peter Turney)', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 155, 'num_features': 19, 'feature_types': ['Categorical', 'Integer', 'Real'], 'demographics': [], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1983, 'last_updated': 'Fri Nov 03 2023', 'dataset_doi': '10.24432/C5Q59J', 'creators': [], 'intro_paper': None, 'additional_info': {'summary': 'Please ask Gail Gong for further information on this database.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '     1. Class: DIE, LIVE\\r\\n     2. AGE: 10, 20, 30, 40, 50, 60, 70, 80\\r\\n     3. SEX: male, female\\r\\n     4. STEROID: no, yes\\r\\n     5. ANTIVIRALS: no, yes\\r\\n     6. FATIGUE: no, yes\\r\\n     7. MALAISE: no, yes\\r\\n     8. ANOREXIA: no, yes\\r\\n     9. LIVER BIG: no, yes\\r\\n    10. LIVER FIRM: no, yes\\r\\n    11. SPLEEN PALPABLE: no, yes\\r\\n    12. SPIDERS: no, yes\\r\\n    13. ASCITES: no, yes\\r\\n    14. VARICES: no, yes\\r\\n    15. BILIRUBIN: 0.39, 0.80, 1.20, 2.00, 3.00, 4.00\\r\\n        -- see the note below\\r\\n    16. ALK PHOSPHATE: 33, 80, 120, 160, 200, 250\\r\\n    17. SGOT: 13, 100, 200, 300, 400, 500, \\r\\n    18. ALBUMIN: 2.1, 3.0, 3.8, 4.5, 5.0, 6.0\\r\\n    19. PROTIME: 10, 20, 30, 40, 50, 60, 70, 80, 90\\r\\n    20. HISTOLOGY: no, yes\\r\\n\\r\\nThe BILIRUBIN attribute appears to be continuously-valued.  I checked this with the donater, Bojan Cestnik, who replied:\\r\\n\\r\\n About the hepatitis database and BILIRUBIN problem I would like to say the following: BILIRUBIN is continuous attribute (= the number of it\\'s \"values\" in the ASDOHEPA.DAT file is negative!!!); \"values\" are quoted because when speaking about the continuous attribute there is no such thing as all possible values. However, they represent so called \"boundary\" values; according to these \"boundary\" values the attribute can be discretized. At the same time, because of the continious attribute, one can perform some other test since the continuous information is preserved. I hope that these lines have at least roughly answered your question. ', 'citation': None}}\n",
      "               name     role         type demographic description units  \\\n",
      "0             Class   Target  Categorical        None        None  None   \n",
      "1               Age  Feature      Integer        None        None  None   \n",
      "2               Sex  Feature  Categorical        None        None  None   \n",
      "3           Steroid  Feature  Categorical        None        None  None   \n",
      "4        Antivirals  Feature  Categorical        None        None  None   \n",
      "5           Fatigue  Feature  Categorical        None        None  None   \n",
      "6           Malaise  Feature  Categorical        None        None  None   \n",
      "7          Anorexia  Feature  Categorical        None        None  None   \n",
      "8         Liver Big  Feature  Categorical        None        None  None   \n",
      "9        Liver Firm  Feature  Categorical        None        None  None   \n",
      "10  Spleen Palpable  Feature  Categorical        None        None  None   \n",
      "11          Spiders  Feature  Categorical        None        None  None   \n",
      "12          Ascites  Feature  Categorical        None        None  None   \n",
      "13          Varices  Feature  Categorical        None        None  None   \n",
      "14        Bilirubin  Feature   Continuous        None        None  None   \n",
      "15    Alk Phosphate  Feature      Integer        None        None  None   \n",
      "16             Sgot  Feature      Integer        None        None  None   \n",
      "17          Albumin  Feature      Integer        None        None  None   \n",
      "18          Protime  Feature      Integer        None        None  None   \n",
      "19        Histology  Feature      Integer        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3             yes  \n",
      "4              no  \n",
      "5             yes  \n",
      "6             yes  \n",
      "7             yes  \n",
      "8             yes  \n",
      "9             yes  \n",
      "10            yes  \n",
      "11            yes  \n",
      "12            yes  \n",
      "13            yes  \n",
      "14            yes  \n",
      "15            yes  \n",
      "16            yes  \n",
      "17            yes  \n",
      "18            yes  \n",
      "19             no  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "hepatitis = fetch_ucirepo(id=46) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = hepatitis.data.features \n",
    "y = hepatitis.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(hepatitis.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(hepatitis.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "82a4f039-d0b9-4220-b4d3-3a12608d0771",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(X.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f8c72d12-9dff-4ade-9d2f-458554af2300",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_data = X.copy()\n",
    "training_data['Class'] = y.values\n",
    "\n",
    "training_data = [(training[0:19], training[19]) for training in training_data.to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2618b7d0-bdc1-443e-830c-3fb22909e981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([30.,  2.,  1.,  2.,  2.,  2.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 18.,  4., 61.,  1.]),\n",
       "  2.0),\n",
       " (array([ 50. ,   1. ,   1. ,   2. ,   1. ,   2. ,   2. ,   1. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.9, 135. ,  42. ,   3.5,  61. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([78. ,  1. ,  2. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 96. , 32. ,  4. , 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([31. ,  1. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 46. , 52. ,  4. , 80. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 34.,   1.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,\n",
       "           2.,   2.,   1.,  85., 200.,   4.,  61.,   1.]),\n",
       "  2.0),\n",
       " (array([34. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.9, 95. , 28. ,  4. , 75. ,  1. ]),\n",
       "  2.0),\n",
       " (array([51.,  1.,  1.,  2.,  1.,  2.,  1.,  2.,  2.,  1.,  1.,  2.,  2.,\n",
       "          1., 85., 58.,  4., 61.,  1.]),\n",
       "  1.0),\n",
       " (array([23.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 58.,  4., 61.,  1.]),\n",
       "  2.0),\n",
       " (array([39. ,  1. ,  2. ,  2. ,  1. ,  2. ,  2. ,  2. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 85. , 48. ,  4.4, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 30. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1. ,  85. , 120. ,   3.9,  61. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([39. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  1. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1.3, 78. , 30. ,  4.4, 85. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 32. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   1. ,  59. , 249. ,   3.7,  54. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([41. ,  1. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.9, 81. , 60. ,  3.9, 52. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 30. ,   1. ,   2. ,   2. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   2.2,  57. , 144. ,   4.9,  78. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([47.,  1.,  1.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 60.,  4., 61.,  1.]),\n",
       "  2.0),\n",
       " (array([38. ,  1. ,  1. ,  2. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          1. ,  2. ,  2. , 72. , 89. ,  2.9, 46. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 66. ,   1. ,   2. ,   2. ,   1. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.2, 102. ,  53. ,   4.3,  61. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 40. ,   1. ,   1. ,   2. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.6,  62. , 166. ,   4. ,  63. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([38. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 53. , 42. ,  4.1, 85. ,  2. ]),\n",
       "  2.0),\n",
       " (array([38. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  1. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 70. , 28. ,  4.2, 62. ,  1. ]),\n",
       "  2.0),\n",
       " (array([22. ,  2. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.9, 48. , 20. ,  4.2, 64. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 27. ,   1. ,   2. ,   2. ,   1. ,   1. ,   1. ,   1. ,   1. ,\n",
       "           1. ,   1. ,   2. ,   2. ,   1.2, 133. ,  98. ,   4.1,  39. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 31.,   1.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,\n",
       "           2.,   2.,   1.,  85.,  20.,   4., 100.,   1.]),\n",
       "  2.0),\n",
       " (array([42. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.9, 60. , 63. ,  4.7, 47. ,  1. ]),\n",
       "  2.0),\n",
       " (array([25. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.4, 45. , 18. ,  4.3, 70. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 27. ,   1. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.8,  95. ,  46. ,   3.8, 100. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([49. ,  1. ,  1. ,  1. ,  1. ,  1. ,  1. ,  2. ,  1. ,  2. ,  1. ,\n",
       "          2. ,  2. ,  0.6, 85. , 48. ,  3.7, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 58. ,   2. ,   2. ,   2. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   1.4, 175. ,  55. ,   2.7,  36. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 61. ,   1. ,   1. ,   2. ,   1. ,   2. ,   2. ,   1. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.3,  78. ,  25. ,   3.8, 100. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([51. ,  1. ,  1. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1. , 78. , 58. ,  4.6, 52. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 39. ,   1. ,   1. ,   1. ,   1. ,   1. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   2.3, 280. ,  98. ,   3.8,  40. ,\n",
       "           1. ]),\n",
       "  1.0),\n",
       " (array([62.,  1.,  1.,  2.,  1.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 60.,  4., 61.,  1.]),\n",
       "  1.0),\n",
       " (array([41. ,  2. ,  2. ,  1. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 81. , 53. ,  5. , 74. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 26. ,   2. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.5, 135. ,  29. ,   3.8,  60. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([35. ,  1. ,  2. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.9, 58. , 92. ,  4.3, 73. ,  1. ]),\n",
       "  2.0),\n",
       " (array([37. ,  1. ,  2. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  1. ,\n",
       "          2. ,  2. ,  0.6, 67. , 28. ,  4.2, 61. ,  1. ]),\n",
       "  1.0),\n",
       " (array([ 23. ,   1. ,   2. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           1. ,   2. ,   2. ,   2. ,   1.3, 194. , 150. ,   4.1,  90. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 20. ,   2. ,   1. ,   2. ,   1. ,   1. ,   1. ,   1. ,   1. ,\n",
       "           1. ,   1. ,   2. ,   2. ,   2.3, 150. ,  68. ,   3.9,  61. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 42.,   1.,   1.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,\n",
       "           2.,   2.,   1.,  85.,  14.,   4., 100.,   1.]),\n",
       "  2.0),\n",
       " (array([ 65. ,   1. ,   2. ,   2. ,   1. ,   1. ,   2. ,   2. ,   1. ,\n",
       "           1. ,   1. ,   1. ,   2. ,   0.3, 180. ,  53. ,   2.9,  74. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([52. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 75. , 55. ,  4. , 21. ,  1. ]),\n",
       "  2.0),\n",
       " (array([23. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  4.6, 56. , 16. ,  4.6, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([33. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1. , 46. , 90. ,  4.4, 60. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 56. ,   1. ,   1. ,   2. ,   1. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.7,  71. ,  18. ,   4.4, 100. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([34.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 86.,  4., 61.,  1.]),\n",
       "  2.0),\n",
       " (array([ 28. ,   1. ,   2. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.7,  74. , 110. ,   4.4,  61. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([37. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  1. ,  2. ,  1. ,\n",
       "          2. ,  2. ,  0.6, 80. , 80. ,  3.8, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 28. ,   2. ,   2. ,   2. ,   1. ,   1. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.8, 191. , 420. ,   3.3,  46. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([36. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  1. ,  2. ,\n",
       "          2. ,  2. ,  0.8, 85. , 44. ,  4.2, 85. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 38. ,   1. ,   2. ,   1. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   0.7, 125. ,  65. ,   4.2,  77. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([39. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.9, 85. , 60. ,  4. , 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([39.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 20.,  4., 61.,  1.]),\n",
       "  2.0),\n",
       " (array([ 44. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.6, 110. , 145. ,   4.4,  70. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 40. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           1. ,   2. ,   2. ,   2. ,   1.2,  85. ,  31. ,   4. , 100. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([30. ,  1. ,  2. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 50. , 78. ,  4.2, 74. ,  1. ]),\n",
       "  2.0),\n",
       " (array([37. ,  1. ,  1. ,  2. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.8, 92. , 59. ,  4. , 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([34.,  1.,  1.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 58.,  4., 61.,  1.]),\n",
       "  2.0),\n",
       " (array([30. ,  1. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 52. , 38. ,  3.9, 52. ,  1. ]),\n",
       "  2.0),\n",
       " (array([64. ,  1. ,  2. ,  1. ,  1. ,  1. ,  2. ,  1. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1. , 80. , 38. ,  4.3, 74. ,  1. ]),\n",
       "  2.0),\n",
       " (array([45.,  2.,  1.,  2.,  1.,  1.,  2.,  2.,  2.,  1.,  2.,  2.,  2.,\n",
       "          1., 85., 75.,  4., 61.,  1.]),\n",
       "  2.0),\n",
       " (array([ 37. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.7,  26. ,  58. ,   4.5, 100. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 32. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.7, 102. ,  64. ,   4. ,  90. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 32. ,   1. ,   2. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           2. ,   1. ,   2. ,   1. ,   3.5, 215. ,  54. ,   3.4,  29. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 36. ,   1. ,   1. ,   2. ,   2. ,   2. ,   2. ,   1. ,   1. ,\n",
       "           1. ,   2. ,   2. ,   2. ,   0.7, 164. ,  44. ,   3.1,  41. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 49. ,   1. ,   2. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.8, 103. ,  43. ,   3.5,  66. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([27. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.8, 85. , 38. ,  4.2, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([56. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 62. , 33. ,  3. , 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([57. ,  1. ,  2. ,  2. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  1. ,\n",
       "          1. ,  2. ,  4.1, 85. , 48. ,  2.6, 73. ,  1. ]),\n",
       "  1.0),\n",
       " (array([39.,  1.,  2.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 34., 15.,  4., 54.,  1.]),\n",
       "  2.0),\n",
       " (array([44. ,  1. ,  1. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1.6, 68. , 68. ,  3.7, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([24. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.8, 82. , 39. ,  4.3, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 34. ,   1. ,   1. ,   2. ,   1. ,   1. ,   2. ,   1. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   2.8, 127. , 182. ,   4. ,  61. ,\n",
       "           1. ]),\n",
       "  1.0),\n",
       " (array([ 51. ,   1. ,   2. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.9,  76. , 271. ,   4.4,  61. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([36.,  1.,  1.,  2.,  1.,  1.,  1.,  2.,  1.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 45.,  4., 57.,  1.]),\n",
       "  2.0),\n",
       " (array([ 50. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.5, 100. , 100. ,   5.3,  61. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([32. ,  1. ,  1. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1. , 55. , 45. ,  4.1, 56. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 58. ,   1. ,   2. ,   2. ,   1. ,   2. ,   2. ,   1. ,   1. ,\n",
       "           1. ,   1. ,   2. ,   2. ,   2. , 167. , 242. ,   3.3,  61. ,\n",
       "           1. ]),\n",
       "  1.0),\n",
       " (array([34. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.6, 30. , 24. ,  4. , 76. ,  1. ]),\n",
       "  2.0),\n",
       " (array([34. ,  1. ,  1. ,  2. ,  1. ,  2. ,  2. ,  1. ,  1. ,  2. ,  1. ,\n",
       "          2. ,  2. ,  1. , 72. , 46. ,  4.4, 57. ,  1. ]),\n",
       "  2.0),\n",
       " (array([28. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 85. , 31. ,  4.9, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([23. ,  1. ,  2. ,  2. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.8, 85. , 14. ,  4.8, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 36. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.7,  62. , 224. ,   4.2, 100. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 30. ,   1. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.7, 100. ,  31. ,   4. , 100. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 67. ,   2. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.5, 179. ,  69. ,   2.9,  61. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 62. ,   2. ,   2. ,   2. ,   1. ,   1. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   1.3, 141. , 156. ,   3.9,  58. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 28. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.6,  44. , 123. ,   4. ,  46. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 44. ,   1. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,\n",
       "           1. ,   2. ,   2. ,   1. ,   0.9, 135. ,  55. ,   4. ,  41. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 30. ,   1. ,   2. ,   2. ,   1. ,   1. ,   1. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   1. ,   1. ,   2.5, 165. ,  64. ,   2.8,  61. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 38. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   1. ,   1. ,   1.2, 118. ,  16. ,   2.8,  61. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([38. ,  1. ,  1. ,  2. ,  1. ,  1. ,  1. ,  1. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.6, 76. , 18. ,  4.4, 84. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 50. ,   2. ,   1. ,   2. ,   1. ,   2. ,   2. ,   1. ,   1. ,\n",
       "           1. ,   1. ,   2. ,   2. ,   0.9, 230. , 117. ,   3.4,  41. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([42. ,  1. ,  1. ,  2. ,  1. ,  1. ,  1. ,  2. ,  2. ,  1. ,  1. ,\n",
       "          2. ,  1. ,  4.6, 85. , 55. ,  3.3, 61. ,  2. ]),\n",
       "  1.0),\n",
       " (array([33.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 60.,  4., 61.,  2.]),\n",
       "  2.0),\n",
       " (array([52. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1.5, 85. , 69. ,  2.9, 61. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 59. ,   1. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   1. ,\n",
       "           1. ,   1. ,   2. ,   2. ,   1.5, 107. , 157. ,   3.6,  38. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([40. ,  1. ,  1. ,  1. ,  1. ,  1. ,  1. ,  1. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.6, 40. , 69. ,  4.2, 67. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 30. ,   1. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   0.8, 147. , 128. ,   3.9, 100. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 44. ,   1. ,   1. ,   2. ,   1. ,   1. ,   2. ,   1. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   3. , 114. ,  65. ,   3.5,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([47. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  1. ,\n",
       "          2. ,  1. ,  2. , 84. , 23. ,  4.2, 66. ,  2. ]),\n",
       "  1.0),\n",
       " (array([60.,  1.,  1.,  2.,  1.,  2.,  2.,  1.,  1.,  1.,  1.,  2.,  2.,\n",
       "          1., 85., 40.,  4., 61.,  2.]),\n",
       "  2.0),\n",
       " (array([ 48. ,   1. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   1. ,   1. ,   4.8, 123. , 157. ,   2.7,  31. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([22. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 85. , 24. ,  4. , 61. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 27. ,   1. ,   1. ,   2. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   2.4, 168. , 227. ,   3. ,  66. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 51. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   2. ,   1. ,\n",
       "           1. ,   1. ,   2. ,   1. ,   4.6, 215. , 269. ,   3.9,  51. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([47. ,  1. ,  2. ,  2. ,  1. ,  1. ,  2. ,  2. ,  1. ,  2. ,  2. ,\n",
       "          1. ,  1. ,  1.7, 86. , 20. ,  2.1, 46. ,  2. ]),\n",
       "  1.0),\n",
       " (array([25. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.6, 85. , 34. ,  6.4, 61. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 35. ,   1. ,   1. ,   2. ,   1. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           1. ,   1. ,   1. ,   2. ,   1.5, 138. ,  58. ,   2.6,  61. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 45. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   2.3,  85. , 648. ,   4. ,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 54. ,   1. ,   1. ,   1. ,   2. ,   2. ,   2. ,   1. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1. , 155. , 225. ,   3.6,  67. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([33. ,  1. ,  1. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          1. ,  2. ,  0.7, 63. , 80. ,  3. , 31. ,  2. ]),\n",
       "  1.0),\n",
       " (array([  7. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           1. ,   2. ,   2. ,   2. ,   0.7, 256. ,  25. ,   4.2,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([42. ,  1. ,  1. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  1. ,\n",
       "          2. ,  2. ,  0.5, 62. , 68. ,  3.8, 29. ,  2. ]),\n",
       "  1.0),\n",
       " (array([52.,  1.,  1.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 30.,  4., 61.,  2.]),\n",
       "  2.0),\n",
       " (array([45. ,  1. ,  1. ,  2. ,  1. ,  2. ,  2. ,  2. ,  1. ,  1. ,  2. ,\n",
       "          2. ,  2. ,  1.2, 81. , 65. ,  3. , 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 36. ,   1. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.1, 141. ,  75. ,   3.3,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 69. ,   2. ,   2. ,   2. ,   1. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   3.2, 119. , 136. ,   4. ,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([24. ,  1. ,  1. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1. , 85. , 34. ,  4.1, 61. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 50. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1. , 139. ,  81. ,   3.9,  62. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([61.,  1.,  1.,  2.,  1.,  1.,  2.,  2.,  2.,  2.,  1.,  2.,  2.,\n",
       "          1., 85., 58.,  4., 61.,  2.]),\n",
       "  1.0),\n",
       " (array([54. ,  1. ,  2. ,  2. ,  1. ,  2. ,  2. ,  1. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  3.2, 85. , 28. ,  3.8, 61. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 56. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   1. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   2.9,  90. , 153. ,   4. ,  61. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 20. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           2. ,   1. ,   1. ,   2. ,   1. , 160. , 118. ,   2.9,  23. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([42. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  1. ,  2. ,\n",
       "          2. ,  2. ,  1.5, 85. , 40. ,  4. , 61. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 37. ,   1. ,   1. ,   2. ,   1. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   0.9,  85. , 231. ,   4.3,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([50.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  1.,  1.,  1.,  2.,  2.,\n",
       "          1., 85., 75.,  4., 72.,  2.]),\n",
       "  2.0),\n",
       " (array([ 34. ,   2. ,   2. ,   2. ,   1. ,   1. ,   1. ,   1. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   0.7,  70. ,  24. ,   4.1, 100. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([28.,  1.,  2.,  2.,  1.,  1.,  1.,  2.,  2.,  2.,  1.,  1.,  2.,\n",
       "          1., 85., 20.,  4., 61.,  2.]),\n",
       "  2.0),\n",
       " (array([ 50. ,   1. ,   2. ,   2. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           1. ,   2. ,   1. ,   1. ,   2.8, 155. ,  75. ,   2.4,  32. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([54. ,  1. ,  1. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          1. ,  2. ,  1.2, 85. , 92. ,  3.1, 66. ,  2. ]),\n",
       "  2.0),\n",
       " (array([57. ,  1. ,  1. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  1. ,\n",
       "          1. ,  2. ,  4.6, 82. , 55. ,  3.3, 30. ,  2. ]),\n",
       "  1.0),\n",
       " (array([54. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1. , 85. , 30. ,  4.5,  0. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 31. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           1. ,   2. ,   2. ,   2. ,   8. ,  85. , 101. ,   2.2,  61. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 48. ,   1. ,   2. ,   2. ,   1. ,   1. ,   1. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   2. , 158. , 278. ,   3.8,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 72. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1. , 115. ,  52. ,   3.4,  50. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 38. ,   1. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.4, 243. ,  49. ,   3.8,  90. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 25. ,   1. ,   2. ,   2. ,   1. ,   2. ,   2. ,   1. ,   1. ,\n",
       "           1. ,   1. ,   1. ,   1. ,   1.3, 181. , 181. ,   4.5,  57. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([51. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  1. ,  1. ,  2. ,  1. ,\n",
       "          2. ,  2. ,  0.8, 85. , 33. ,  4.5, 61. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 38. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   1. ,   1.6, 130. , 140. ,   3.5,  56. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 47. ,   1. ,   2. ,   2. ,   1. ,   1. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   1. ,   1. ,   1. , 166. ,  30. ,   2.6,  31. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([45. ,  1. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1.3, 85. , 44. ,  4.2, 85. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 36. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   1. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   1. ,   1.7, 295. ,  60. ,   2.7,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 54. ,   1. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,\n",
       "           1. ,   2. ,   1. ,   2. ,   3.9, 120. ,  28. ,   3.5,  43. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([51.,  1.,  2.,  2.,  1.,  2.,  2.,  2.,  1.,  1.,  1.,  2.,  1.,\n",
       "          1., 85., 20.,  3., 63.,  2.]),\n",
       "  2.0),\n",
       " (array([49. ,  1. ,  1. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  1. ,  1. ,\n",
       "          2. ,  2. ,  1.4, 85. , 70. ,  3.5, 35. ,  2. ]),\n",
       "  1.0),\n",
       " (array([ 45. ,   1. ,   2. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           2. ,   1. ,   1. ,   2. ,   1.9,  85. , 114. ,   2.4,  61. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 31. ,   1. ,   1. ,   2. ,   1. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.2,  75. , 173. ,   4.2,  54. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 41. ,   1. ,   2. ,   2. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           1. ,   1. ,   2. ,   1. ,   4.2,  65. , 120. ,   3.4,  61. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 70. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.7, 109. , 528. ,   2.8,  35. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 20. ,   1. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.9,  89. , 152. ,   4. ,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 36. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.6, 120. ,  30. ,   4. ,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 46. ,   1. ,   2. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           2. ,   1. ,   1. ,   1. ,   7.6,  85. , 242. ,   3.3,  50. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 44. ,   1. ,   2. ,   2. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.9, 126. , 142. ,   4.3,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([61. ,  1. ,  1. ,  2. ,  1. ,  1. ,  2. ,  1. ,  1. ,  2. ,  1. ,\n",
       "          2. ,  2. ,  0.8, 75. , 20. ,  4.1, 61. ,  2. ]),\n",
       "  2.0),\n",
       " (array([53. ,  2. ,  1. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  1. ,  1. ,\n",
       "          2. ,  1. ,  1.5, 81. , 19. ,  4.1, 48. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 43. ,   1. ,   2. ,   2. ,   1. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           1. ,   1. ,   1. ,   2. ,   1.2, 100. ,  19. ,   3.1,  42. ,\n",
       "           2. ]),\n",
       "  1.0)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "821d8472-aca9-4c3f-8abe-8b4720cb9191",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (32,32) and (19,) not aligned: 32 (dim 1) != 19 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m net \u001b[38;5;241m=\u001b[39m Network([\u001b[38;5;241m19\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m2\u001b[39m])\n",
      "Cell \u001b[1;32mIn[83], line 58\u001b[0m, in \u001b[0;36mNetwork.SGD\u001b[1;34m(self, training_data, epochs, mini_batch_size, eta, test_data)\u001b[0m\n\u001b[0;32m     53\u001b[0m mini_batches \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     54\u001b[0m     training_data[k:k\u001b[38;5;241m+\u001b[39mmini_batch_size]\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, n, mini_batch_size)\n\u001b[0;32m     56\u001b[0m ]\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mini_batch \u001b[38;5;129;01min\u001b[39;00m mini_batches:\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_mini_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmini_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m test_data:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(j,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(test_data),n_test));\n",
      "Cell \u001b[1;32mIn[83], line 72\u001b[0m, in \u001b[0;36mNetwork.update_mini_batch\u001b[1;34m(self, mini_batch, eta)\u001b[0m\n\u001b[0;32m     70\u001b[0m nabla_w \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mzeros(w\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights]\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m mini_batch:\n\u001b[1;32m---> 72\u001b[0m     delta_nabla_b, delta_nabla_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackprop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     nabla_b \u001b[38;5;241m=\u001b[39m [nb\u001b[38;5;241m+\u001b[39mdnb \u001b[38;5;28;01mfor\u001b[39;00m nb, dnb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(nabla_b, delta_nabla_b)]\n\u001b[0;32m     74\u001b[0m     nabla_w \u001b[38;5;241m=\u001b[39m [nw\u001b[38;5;241m+\u001b[39mdnw \u001b[38;5;28;01mfor\u001b[39;00m nw, dnw \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(nabla_w, delta_nabla_w)]\n",
      "Cell \u001b[1;32mIn[83], line 112\u001b[0m, in \u001b[0;36mNetwork.backprop\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    110\u001b[0m     delta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;241m-\u001b[39ml\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtranspose(), delta) \u001b[38;5;241m*\u001b[39m sp\n\u001b[0;32m    111\u001b[0m     nabla_b[\u001b[38;5;241m-\u001b[39ml] \u001b[38;5;241m=\u001b[39m delta\n\u001b[1;32m--> 112\u001b[0m     nabla_w[\u001b[38;5;241m-\u001b[39ml] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43ml\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (nabla_b, nabla_w)\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (32,32) and (19,) not aligned: 32 (dim 1) != 19 (dim 0)"
     ]
    }
   ],
   "source": [
    "net.SGD(training_data, 30, 10, 3.0)\n",
    "net = Network([19, 32, 16, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59085f2-3e3a-4ab1-b059-f7277f5e292d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315efc4b-c0a0-4d59-bace-1a3702fa1e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8d0d5899-e13f-486a-ac33-9b0837b65885",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 20 is out of bounds for axis 0 with size 19",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\comp258-FNsmQjYB-py3.10\\lib\\site-packages\\pandas\\core\\frame.py:5159\u001b[0m, in \u001b[0;36mDataFrame.insert\u001b[1;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   5156\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   5158\u001b[0m value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[1;32m-> 5159\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\comp258-FNsmQjYB-py3.10\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1366\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[1;34m(self, loc, item, value, refs)\u001b[0m\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m   1360\u001b[0m     \u001b[38;5;66;03m# TODO: re-issue this with setitem-specific message?\u001b[39;00m\n\u001b[0;32m   1361\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[0;32m   1362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe behavior of Index.insert with object-dtype is deprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1364\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   1365\u001b[0m     )\n\u001b[1;32m-> 1366\u001b[0m     new_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1369\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\comp258-FNsmQjYB-py3.10\\lib\\site-packages\\pandas\\core\\indexes\\base.py:7002\u001b[0m, in \u001b[0;36mIndex.insert\u001b[1;34m(self, loc, item)\u001b[0m\n\u001b[0;32m   6995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   6996\u001b[0m     item, (\u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mdatetime64, np\u001b[38;5;241m.\u001b[39mtimedelta64)\n\u001b[0;32m   6997\u001b[0m ):\n\u001b[0;32m   6998\u001b[0m     \u001b[38;5;66;03m# with object-dtype we need to worry about numpy incorrectly casting\u001b[39;00m\n\u001b[0;32m   6999\u001b[0m     \u001b[38;5;66;03m# dt64/td64 to integer, also about treating tuples as sequences\u001b[39;00m\n\u001b[0;32m   7000\u001b[0m     \u001b[38;5;66;03m# special-casing dt64/td64 https://github.com/numpy/numpy/issues/12550\u001b[39;00m\n\u001b[0;32m   7001\u001b[0m     casted \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(item)\n\u001b[1;32m-> 7002\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   7004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   7005\u001b[0m     \u001b[38;5;66;03m# error: No overload variant of \"insert\" matches argument types\u001b[39;00m\n\u001b[0;32m   7006\u001b[0m     \u001b[38;5;66;03m# \"ndarray[Any, Any]\", \"int\", \"None\"\u001b[39;00m\n\u001b[0;32m   7007\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minsert(arr, loc, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\comp258-FNsmQjYB-py3.10\\lib\\site-packages\\numpy\\lib\\function_base.py:5505\u001b[0m, in \u001b[0;36minsert\u001b[1;34m(arr, obj, values, axis)\u001b[0m\n\u001b[0;32m   5503\u001b[0m index \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   5504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mN \u001b[38;5;129;01mor\u001b[39;00m index \u001b[38;5;241m>\u001b[39m N:\n\u001b[1;32m-> 5505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is out of bounds for axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5506\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (index \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   5508\u001b[0m     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m N\n",
      "\u001b[1;31mIndexError\u001b[0m: index 20 is out of bounds for axis 0 with size 19"
     ]
    }
   ],
   "source": [
    "X.insert(20, \"Class\", y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
