{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efbe11d8-6afb-4c1f-8ad8-142215285439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 46, 'name': 'Hepatitis', 'repository_url': 'https://archive.ics.uci.edu/dataset/46/hepatitis', 'data_url': 'https://archive.ics.uci.edu/static/public/46/data.csv', 'abstract': 'From G.Gong: CMU; Mostly Boolean or numeric-valued attribute types; Includes cost data (donated by Peter Turney)', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 155, 'num_features': 19, 'feature_types': ['Categorical', 'Integer', 'Real'], 'demographics': [], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1983, 'last_updated': 'Fri Nov 03 2023', 'dataset_doi': '10.24432/C5Q59J', 'creators': [], 'intro_paper': None, 'additional_info': {'summary': 'Please ask Gail Gong for further information on this database.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '     1. Class: DIE, LIVE\\r\\n     2. AGE: 10, 20, 30, 40, 50, 60, 70, 80\\r\\n     3. SEX: male, female\\r\\n     4. STEROID: no, yes\\r\\n     5. ANTIVIRALS: no, yes\\r\\n     6. FATIGUE: no, yes\\r\\n     7. MALAISE: no, yes\\r\\n     8. ANOREXIA: no, yes\\r\\n     9. LIVER BIG: no, yes\\r\\n    10. LIVER FIRM: no, yes\\r\\n    11. SPLEEN PALPABLE: no, yes\\r\\n    12. SPIDERS: no, yes\\r\\n    13. ASCITES: no, yes\\r\\n    14. VARICES: no, yes\\r\\n    15. BILIRUBIN: 0.39, 0.80, 1.20, 2.00, 3.00, 4.00\\r\\n        -- see the note below\\r\\n    16. ALK PHOSPHATE: 33, 80, 120, 160, 200, 250\\r\\n    17. SGOT: 13, 100, 200, 300, 400, 500, \\r\\n    18. ALBUMIN: 2.1, 3.0, 3.8, 4.5, 5.0, 6.0\\r\\n    19. PROTIME: 10, 20, 30, 40, 50, 60, 70, 80, 90\\r\\n    20. HISTOLOGY: no, yes\\r\\n\\r\\nThe BILIRUBIN attribute appears to be continuously-valued.  I checked this with the donater, Bojan Cestnik, who replied:\\r\\n\\r\\n About the hepatitis database and BILIRUBIN problem I would like to say the following: BILIRUBIN is continuous attribute (= the number of it\\'s \"values\" in the ASDOHEPA.DAT file is negative!!!); \"values\" are quoted because when speaking about the continuous attribute there is no such thing as all possible values. However, they represent so called \"boundary\" values; according to these \"boundary\" values the attribute can be discretized. At the same time, because of the continious attribute, one can perform some other test since the continuous information is preserved. I hope that these lines have at least roughly answered your question. ', 'citation': None}}\n",
      "               name     role         type demographic description units  \\\n",
      "0             Class   Target  Categorical        None        None  None   \n",
      "1               Age  Feature      Integer        None        None  None   \n",
      "2               Sex  Feature  Categorical        None        None  None   \n",
      "3           Steroid  Feature  Categorical        None        None  None   \n",
      "4        Antivirals  Feature  Categorical        None        None  None   \n",
      "5           Fatigue  Feature  Categorical        None        None  None   \n",
      "6           Malaise  Feature  Categorical        None        None  None   \n",
      "7          Anorexia  Feature  Categorical        None        None  None   \n",
      "8         Liver Big  Feature  Categorical        None        None  None   \n",
      "9        Liver Firm  Feature  Categorical        None        None  None   \n",
      "10  Spleen Palpable  Feature  Categorical        None        None  None   \n",
      "11          Spiders  Feature  Categorical        None        None  None   \n",
      "12          Ascites  Feature  Categorical        None        None  None   \n",
      "13          Varices  Feature  Categorical        None        None  None   \n",
      "14        Bilirubin  Feature   Continuous        None        None  None   \n",
      "15    Alk Phosphate  Feature      Integer        None        None  None   \n",
      "16             Sgot  Feature      Integer        None        None  None   \n",
      "17          Albumin  Feature      Integer        None        None  None   \n",
      "18          Protime  Feature      Integer        None        None  None   \n",
      "19        Histology  Feature      Integer        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3             yes  \n",
      "4              no  \n",
      "5             yes  \n",
      "6             yes  \n",
      "7             yes  \n",
      "8             yes  \n",
      "9             yes  \n",
      "10            yes  \n",
      "11            yes  \n",
      "12            yes  \n",
      "13            yes  \n",
      "14            yes  \n",
      "15            yes  \n",
      "16            yes  \n",
      "17            yes  \n",
      "18            yes  \n",
      "19             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "hepatitis = fetch_ucirepo(id=46) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = hepatitis.data.features \n",
    "y = hepatitis.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(hepatitis.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(hepatitis.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9c6af5-e4f6-4fc3-a63d-5e66091bc6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(X.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df54246-a345-4f25-baa4-4d0d9ef69635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Miscellaneous functions\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(z)*(1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "410cba86-2694-4291-b12c-d360b33c0501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "network.py\n",
    "~~~~~~~~~~\n",
    "IT WORKS\n",
    "A module to implement the stochastic gradient descent learning\n",
    "algorithm for a feedforward neural network.  Gradients are calculated\n",
    "using backpropagation.  Note that I have focused on making the code\n",
    "simple, easily readable, and easily modifiable.  It is not optimized,\n",
    "and omits many desirable features.\n",
    "\"\"\"\n",
    "\n",
    "#### Libraries\n",
    "# Standard library\n",
    "import random\n",
    "\n",
    "# Third-party libraries\n",
    "import numpy as np\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"The list ``sizes`` contains the number of neurons in the\n",
    "        respective layers of the network.  For example, if the list\n",
    "        was [2, 3, 1] then it would be a three-layer network, with the\n",
    "        first layer containing 2 neurons, the second layer 3 neurons,\n",
    "        and the third layer 1 neuron.  The biases and weights for the\n",
    "        network are initialized randomly, using a Gaussian\n",
    "        distribution with mean 0, and variance 1.  Note that the first\n",
    "        layer is assumed to be an input layer, and by convention we\n",
    "        won't set any biases for those neurons, since biases are only\n",
    "        ever used in computing the outputs from later layers.\"\"\"\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x)\n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        \"\"\"Return the output of the network if ``a`` is input.\"\"\"\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = sigmoid(np.dot(w, a)+b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, training_data, epochs, mini_batch_size, eta,\n",
    "            test_data=None):\n",
    "        \"\"\"Train the neural network using mini-batch stochastic\n",
    "        gradient descent.  The ``training_data`` is a list of tuples\n",
    "        ``(x, y)`` representing the training inputs and the desired\n",
    "        outputs.  The other non-optional parameters are\n",
    "        self-explanatory.  If ``test_data`` is provided then the\n",
    "        network will be evaluated against the test data after each\n",
    "        epoch, and partial progress printed out.  This is useful for\n",
    "        tracking progress, but slows things down substantially.\"\"\"\n",
    "\n",
    "        training_data = list(training_data)\n",
    "        n = len(training_data)\n",
    "\n",
    "        if test_data:\n",
    "            test_data = list(test_data)\n",
    "            n_test = len(test_data)\n",
    "\n",
    "        for j in range(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batches = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in range(0, n, mini_batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "            if test_data:\n",
    "                print(\"Epoch {} : {} / {}\".format(j,self.evaluate(test_data),n_test));\n",
    "            else:\n",
    "                print(\"Epoch {} complete\".format(j))\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        \"\"\"Update the network's weights and biases by applying\n",
    "        gradient descent using backpropagation to a single mini batch.\n",
    "        The ``mini_batch`` is a list of tuples ``(x, y)``, and ``eta``\n",
    "        is the learning rate.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.backprop(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.weights = [w-(eta/len(mini_batch))*nw\n",
    "                        for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b-(eta/len(mini_batch))*nb\n",
    "                       for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        \"\"\"Return a tuple ``(nabla_b, nabla_w)`` representing the\n",
    "        gradient for the cost function C_x.  ``nabla_b`` and\n",
    "        ``nabla_w`` are layer-by-layer lists of numpy arrays, similar\n",
    "        to ``self.biases`` and ``self.weights``.\"\"\"\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        # feedforward\n",
    "        activation = x\n",
    "        activations = [x] # list to store all the activations, layer by layer\n",
    "        zs = [] # list to store all the z vectors, layer by layer\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation)+b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "        # backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * \\\n",
    "            sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        # Note that the variable l in the loop below is used a little\n",
    "        # differently to the notation in Chapter 2 of the book.  Here,\n",
    "        # l = 1 means the last layer of neurons, l = 2 is the\n",
    "        # second-last layer, and so on.  It's a renumbering of the\n",
    "        # scheme in the book, used here to take advantage of the fact\n",
    "        # that Python can use negative indices in lists.\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
    "                        for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
    "        \\partial a for the output activations.\"\"\"\n",
    "        return (output_activations-y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a57d510-ad28-481c-a64f-326a6666b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "XAndY = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beafc546-bc14-49c0-8ff0-32d7e2001176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Steroid</th>\n",
       "      <th>Antivirals</th>\n",
       "      <th>Fatigue</th>\n",
       "      <th>Malaise</th>\n",
       "      <th>Anorexia</th>\n",
       "      <th>Liver Big</th>\n",
       "      <th>Liver Firm</th>\n",
       "      <th>Spleen Palpable</th>\n",
       "      <th>Spiders</th>\n",
       "      <th>Ascites</th>\n",
       "      <th>Varices</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Alk Phosphate</th>\n",
       "      <th>Sgot</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>Protime</th>\n",
       "      <th>Histology</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>135.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>96.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>46.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>126.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>75.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>81.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  Sex  Steroid  Antivirals  Fatigue  Malaise  Anorexia  Liver Big  \\\n",
       "0     30    2      1.0           2      2.0      2.0       2.0        1.0   \n",
       "1     50    1      1.0           2      1.0      2.0       2.0        1.0   \n",
       "2     78    1      2.0           2      1.0      2.0       2.0        2.0   \n",
       "3     31    1      2.0           1      2.0      2.0       2.0        2.0   \n",
       "4     34    1      2.0           2      2.0      2.0       2.0        2.0   \n",
       "..   ...  ...      ...         ...      ...      ...       ...        ...   \n",
       "150   46    1      2.0           2      1.0      1.0       1.0        2.0   \n",
       "151   44    1      2.0           2      1.0      2.0       2.0        2.0   \n",
       "152   61    1      1.0           2      1.0      1.0       2.0        1.0   \n",
       "153   53    2      1.0           2      1.0      2.0       2.0        2.0   \n",
       "154   43    1      2.0           2      1.0      2.0       2.0        2.0   \n",
       "\n",
       "     Liver Firm  Spleen Palpable  Spiders  Ascites  Varices  Bilirubin  \\\n",
       "0           2.0              2.0      2.0      2.0      2.0        1.0   \n",
       "1           2.0              2.0      2.0      2.0      2.0        0.9   \n",
       "2           2.0              2.0      2.0      2.0      2.0        0.7   \n",
       "3           2.0              2.0      2.0      2.0      2.0        0.7   \n",
       "4           2.0              2.0      2.0      2.0      2.0        1.0   \n",
       "..          ...              ...      ...      ...      ...        ...   \n",
       "150         2.0              2.0      1.0      1.0      1.0        7.6   \n",
       "151         1.0              2.0      2.0      2.0      2.0        0.9   \n",
       "152         1.0              2.0      1.0      2.0      2.0        0.8   \n",
       "153         2.0              1.0      1.0      2.0      1.0        1.5   \n",
       "154         2.0              1.0      1.0      1.0      2.0        1.2   \n",
       "\n",
       "     Alk Phosphate   Sgot  Albumin  Protime  Histology  Class  \n",
       "0             85.0   18.0      4.0     61.0          1      2  \n",
       "1            135.0   42.0      3.5     61.0          1      2  \n",
       "2             96.0   32.0      4.0     61.0          1      2  \n",
       "3             46.0   52.0      4.0     80.0          1      2  \n",
       "4             85.0  200.0      4.0     61.0          1      2  \n",
       "..             ...    ...      ...      ...        ...    ...  \n",
       "150           85.0  242.0      3.3     50.0          2      1  \n",
       "151          126.0  142.0      4.3     61.0          2      2  \n",
       "152           75.0   20.0      4.1     61.0          2      2  \n",
       "153           81.0   19.0      4.1     48.0          2      2  \n",
       "154          100.0   19.0      3.1     42.0          2      1  \n",
       "\n",
       "[155 rows x 20 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XAndY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11ec3573-c0ca-4695-b349-df3771f8a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [(row[0:19], row[19]) for row in XAndY.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1a0544d-9272-4b0e-b58a-d66a9cf3db1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([30.,  2.,  1.,  2.,  2.,  2.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 18.,  4., 61.,  1.]),\n",
       "  2.0),\n",
       " (array([ 50. ,   1. ,   1. ,   2. ,   1. ,   2. ,   2. ,   1. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.9, 135. ,  42. ,   3.5,  61. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([78. ,  1. ,  2. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 96. , 32. ,  4. , 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([31. ,  1. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 46. , 52. ,  4. , 80. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 34.,   1.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,\n",
       "           2.,   2.,   1.,  85., 200.,   4.,  61.,   1.]),\n",
       "  2.0),\n",
       " (array([34. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.9, 95. , 28. ,  4. , 75. ,  1. ]),\n",
       "  2.0),\n",
       " (array([51.,  1.,  1.,  2.,  1.,  2.,  1.,  2.,  2.,  1.,  1.,  2.,  2.,\n",
       "          1., 85., 58.,  4., 61.,  1.]),\n",
       "  1.0),\n",
       " (array([23.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 58.,  4., 61.,  1.]),\n",
       "  2.0),\n",
       " (array([39. ,  1. ,  2. ,  2. ,  1. ,  2. ,  2. ,  2. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 85. , 48. ,  4.4, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 30. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1. ,  85. , 120. ,   3.9,  61. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([39. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  1. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1.3, 78. , 30. ,  4.4, 85. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 32. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   1. ,  59. , 249. ,   3.7,  54. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([41. ,  1. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.9, 81. , 60. ,  3.9, 52. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 30. ,   1. ,   2. ,   2. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   2.2,  57. , 144. ,   4.9,  78. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([47.,  1.,  1.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 60.,  4., 61.,  1.]),\n",
       "  2.0),\n",
       " (array([38. ,  1. ,  1. ,  2. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          1. ,  2. ,  2. , 72. , 89. ,  2.9, 46. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 66. ,   1. ,   2. ,   2. ,   1. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.2, 102. ,  53. ,   4.3,  61. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 40. ,   1. ,   1. ,   2. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.6,  62. , 166. ,   4. ,  63. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([38. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 53. , 42. ,  4.1, 85. ,  2. ]),\n",
       "  2.0),\n",
       " (array([38. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  1. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 70. , 28. ,  4.2, 62. ,  1. ]),\n",
       "  2.0),\n",
       " (array([22. ,  2. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.9, 48. , 20. ,  4.2, 64. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 27. ,   1. ,   2. ,   2. ,   1. ,   1. ,   1. ,   1. ,   1. ,\n",
       "           1. ,   1. ,   2. ,   2. ,   1.2, 133. ,  98. ,   4.1,  39. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 31.,   1.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,\n",
       "           2.,   2.,   1.,  85.,  20.,   4., 100.,   1.]),\n",
       "  2.0),\n",
       " (array([42. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.9, 60. , 63. ,  4.7, 47. ,  1. ]),\n",
       "  2.0),\n",
       " (array([25. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.4, 45. , 18. ,  4.3, 70. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 27. ,   1. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.8,  95. ,  46. ,   3.8, 100. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([49. ,  1. ,  1. ,  1. ,  1. ,  1. ,  1. ,  2. ,  1. ,  2. ,  1. ,\n",
       "          2. ,  2. ,  0.6, 85. , 48. ,  3.7, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 58. ,   2. ,   2. ,   2. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   1.4, 175. ,  55. ,   2.7,  36. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 61. ,   1. ,   1. ,   2. ,   1. ,   2. ,   2. ,   1. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.3,  78. ,  25. ,   3.8, 100. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([51. ,  1. ,  1. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1. , 78. , 58. ,  4.6, 52. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 39. ,   1. ,   1. ,   1. ,   1. ,   1. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   2.3, 280. ,  98. ,   3.8,  40. ,\n",
       "           1. ]),\n",
       "  1.0),\n",
       " (array([62.,  1.,  1.,  2.,  1.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 60.,  4., 61.,  1.]),\n",
       "  1.0),\n",
       " (array([41. ,  2. ,  2. ,  1. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 81. , 53. ,  5. , 74. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 26. ,   2. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.5, 135. ,  29. ,   3.8,  60. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([35. ,  1. ,  2. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.9, 58. , 92. ,  4.3, 73. ,  1. ]),\n",
       "  2.0),\n",
       " (array([37. ,  1. ,  2. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  1. ,\n",
       "          2. ,  2. ,  0.6, 67. , 28. ,  4.2, 61. ,  1. ]),\n",
       "  1.0),\n",
       " (array([ 23. ,   1. ,   2. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           1. ,   2. ,   2. ,   2. ,   1.3, 194. , 150. ,   4.1,  90. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 20. ,   2. ,   1. ,   2. ,   1. ,   1. ,   1. ,   1. ,   1. ,\n",
       "           1. ,   1. ,   2. ,   2. ,   2.3, 150. ,  68. ,   3.9,  61. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 42.,   1.,   1.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,   2.,\n",
       "           2.,   2.,   1.,  85.,  14.,   4., 100.,   1.]),\n",
       "  2.0),\n",
       " (array([ 65. ,   1. ,   2. ,   2. ,   1. ,   1. ,   2. ,   2. ,   1. ,\n",
       "           1. ,   1. ,   1. ,   2. ,   0.3, 180. ,  53. ,   2.9,  74. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([52. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 75. , 55. ,  4. , 21. ,  1. ]),\n",
       "  2.0),\n",
       " (array([23. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  4.6, 56. , 16. ,  4.6, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([33. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1. , 46. , 90. ,  4.4, 60. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 56. ,   1. ,   1. ,   2. ,   1. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.7,  71. ,  18. ,   4.4, 100. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([34.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 86.,  4., 61.,  1.]),\n",
       "  2.0),\n",
       " (array([ 28. ,   1. ,   2. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.7,  74. , 110. ,   4.4,  61. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([37. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  1. ,  2. ,  1. ,\n",
       "          2. ,  2. ,  0.6, 80. , 80. ,  3.8, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 28. ,   2. ,   2. ,   2. ,   1. ,   1. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.8, 191. , 420. ,   3.3,  46. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([36. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  1. ,  2. ,\n",
       "          2. ,  2. ,  0.8, 85. , 44. ,  4.2, 85. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 38. ,   1. ,   2. ,   1. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   0.7, 125. ,  65. ,   4.2,  77. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([39. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.9, 85. , 60. ,  4. , 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([39.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 20.,  4., 61.,  1.]),\n",
       "  2.0),\n",
       " (array([ 44. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.6, 110. , 145. ,   4.4,  70. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 40. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           1. ,   2. ,   2. ,   2. ,   1.2,  85. ,  31. ,   4. , 100. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([30. ,  1. ,  2. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 50. , 78. ,  4.2, 74. ,  1. ]),\n",
       "  2.0),\n",
       " (array([37. ,  1. ,  1. ,  2. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.8, 92. , 59. ,  4. , 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([34.,  1.,  1.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 58.,  4., 61.,  1.]),\n",
       "  2.0),\n",
       " (array([30. ,  1. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 52. , 38. ,  3.9, 52. ,  1. ]),\n",
       "  2.0),\n",
       " (array([64. ,  1. ,  2. ,  1. ,  1. ,  1. ,  2. ,  1. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1. , 80. , 38. ,  4.3, 74. ,  1. ]),\n",
       "  2.0),\n",
       " (array([45.,  2.,  1.,  2.,  1.,  1.,  2.,  2.,  2.,  1.,  2.,  2.,  2.,\n",
       "          1., 85., 75.,  4., 61.,  1.]),\n",
       "  2.0),\n",
       " (array([ 37. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.7,  26. ,  58. ,   4.5, 100. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 32. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.7, 102. ,  64. ,   4. ,  90. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 32. ,   1. ,   2. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           2. ,   1. ,   2. ,   1. ,   3.5, 215. ,  54. ,   3.4,  29. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 36. ,   1. ,   1. ,   2. ,   2. ,   2. ,   2. ,   1. ,   1. ,\n",
       "           1. ,   2. ,   2. ,   2. ,   0.7, 164. ,  44. ,   3.1,  41. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 49. ,   1. ,   2. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.8, 103. ,  43. ,   3.5,  66. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([27. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.8, 85. , 38. ,  4.2, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([56. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 62. , 33. ,  3. , 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([57. ,  1. ,  2. ,  2. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  1. ,\n",
       "          1. ,  2. ,  4.1, 85. , 48. ,  2.6, 73. ,  1. ]),\n",
       "  1.0),\n",
       " (array([39.,  1.,  2.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 34., 15.,  4., 54.,  1.]),\n",
       "  2.0),\n",
       " (array([44. ,  1. ,  1. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1.6, 68. , 68. ,  3.7, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([24. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.8, 82. , 39. ,  4.3, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 34. ,   1. ,   1. ,   2. ,   1. ,   1. ,   2. ,   1. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   2.8, 127. , 182. ,   4. ,  61. ,\n",
       "           1. ]),\n",
       "  1.0),\n",
       " (array([ 51. ,   1. ,   2. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.9,  76. , 271. ,   4.4,  61. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([36.,  1.,  1.,  2.,  1.,  1.,  1.,  2.,  1.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 45.,  4., 57.,  1.]),\n",
       "  2.0),\n",
       " (array([ 50. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.5, 100. , 100. ,   5.3,  61. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([32. ,  1. ,  1. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1. , 55. , 45. ,  4.1, 56. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 58. ,   1. ,   2. ,   2. ,   1. ,   2. ,   2. ,   1. ,   1. ,\n",
       "           1. ,   1. ,   2. ,   2. ,   2. , 167. , 242. ,   3.3,  61. ,\n",
       "           1. ]),\n",
       "  1.0),\n",
       " (array([34. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.6, 30. , 24. ,  4. , 76. ,  1. ]),\n",
       "  2.0),\n",
       " (array([34. ,  1. ,  1. ,  2. ,  1. ,  2. ,  2. ,  1. ,  1. ,  2. ,  1. ,\n",
       "          2. ,  2. ,  1. , 72. , 46. ,  4.4, 57. ,  1. ]),\n",
       "  2.0),\n",
       " (array([28. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 85. , 31. ,  4.9, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([23. ,  1. ,  2. ,  2. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.8, 85. , 14. ,  4.8, 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 36. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.7,  62. , 224. ,   4.2, 100. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 30. ,   1. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.7, 100. ,  31. ,   4. , 100. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 67. ,   2. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.5, 179. ,  69. ,   2.9,  61. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 62. ,   2. ,   2. ,   2. ,   1. ,   1. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   1.3, 141. , 156. ,   3.9,  58. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 28. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.6,  44. , 123. ,   4. ,  46. ,\n",
       "           1. ]),\n",
       "  2.0),\n",
       " (array([ 44. ,   1. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,\n",
       "           1. ,   2. ,   2. ,   1. ,   0.9, 135. ,  55. ,   4. ,  41. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 30. ,   1. ,   2. ,   2. ,   1. ,   1. ,   1. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   1. ,   1. ,   2.5, 165. ,  64. ,   2.8,  61. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 38. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   1. ,   1. ,   1.2, 118. ,  16. ,   2.8,  61. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([38. ,  1. ,  1. ,  2. ,  1. ,  1. ,  1. ,  1. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.6, 76. , 18. ,  4.4, 84. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 50. ,   2. ,   1. ,   2. ,   1. ,   2. ,   2. ,   1. ,   1. ,\n",
       "           1. ,   1. ,   2. ,   2. ,   0.9, 230. , 117. ,   3.4,  41. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([42. ,  1. ,  1. ,  2. ,  1. ,  1. ,  1. ,  2. ,  2. ,  1. ,  1. ,\n",
       "          2. ,  1. ,  4.6, 85. , 55. ,  3.3, 61. ,  2. ]),\n",
       "  1.0),\n",
       " (array([33.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 60.,  4., 61.,  2.]),\n",
       "  2.0),\n",
       " (array([52. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1.5, 85. , 69. ,  2.9, 61. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 59. ,   1. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   1. ,\n",
       "           1. ,   1. ,   2. ,   2. ,   1.5, 107. , 157. ,   3.6,  38. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([40. ,  1. ,  1. ,  1. ,  1. ,  1. ,  1. ,  1. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.6, 40. , 69. ,  4.2, 67. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 30. ,   1. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   0.8, 147. , 128. ,   3.9, 100. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 44. ,   1. ,   1. ,   2. ,   1. ,   1. ,   2. ,   1. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   3. , 114. ,  65. ,   3.5,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([47. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  1. ,\n",
       "          2. ,  1. ,  2. , 84. , 23. ,  4.2, 66. ,  2. ]),\n",
       "  1.0),\n",
       " (array([60.,  1.,  1.,  2.,  1.,  2.,  2.,  1.,  1.,  1.,  1.,  2.,  2.,\n",
       "          1., 85., 40.,  4., 61.,  2.]),\n",
       "  2.0),\n",
       " (array([ 48. ,   1. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   1. ,   1. ,   4.8, 123. , 157. ,   2.7,  31. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([22. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.7, 85. , 24. ,  4. , 61. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 27. ,   1. ,   1. ,   2. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   2.4, 168. , 227. ,   3. ,  66. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 51. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   2. ,   1. ,\n",
       "           1. ,   1. ,   2. ,   1. ,   4.6, 215. , 269. ,   3.9,  51. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([47. ,  1. ,  2. ,  2. ,  1. ,  1. ,  2. ,  2. ,  1. ,  2. ,  2. ,\n",
       "          1. ,  1. ,  1.7, 86. , 20. ,  2.1, 46. ,  2. ]),\n",
       "  1.0),\n",
       " (array([25. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  0.6, 85. , 34. ,  6.4, 61. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 35. ,   1. ,   1. ,   2. ,   1. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           1. ,   1. ,   1. ,   2. ,   1.5, 138. ,  58. ,   2.6,  61. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 45. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   2.3,  85. , 648. ,   4. ,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 54. ,   1. ,   1. ,   1. ,   2. ,   2. ,   2. ,   1. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1. , 155. , 225. ,   3.6,  67. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([33. ,  1. ,  1. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          1. ,  2. ,  0.7, 63. , 80. ,  3. , 31. ,  2. ]),\n",
       "  1.0),\n",
       " (array([  7. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           1. ,   2. ,   2. ,   2. ,   0.7, 256. ,  25. ,   4.2,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([42. ,  1. ,  1. ,  1. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  1. ,\n",
       "          2. ,  2. ,  0.5, 62. , 68. ,  3.8, 29. ,  2. ]),\n",
       "  1.0),\n",
       " (array([52.,  1.,  1.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "          1., 85., 30.,  4., 61.,  2.]),\n",
       "  2.0),\n",
       " (array([45. ,  1. ,  1. ,  2. ,  1. ,  2. ,  2. ,  2. ,  1. ,  1. ,  2. ,\n",
       "          2. ,  2. ,  1.2, 81. , 65. ,  3. , 61. ,  1. ]),\n",
       "  2.0),\n",
       " (array([ 36. ,   1. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.1, 141. ,  75. ,   3.3,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 69. ,   2. ,   2. ,   2. ,   1. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   3.2, 119. , 136. ,   4. ,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([24. ,  1. ,  1. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1. , 85. , 34. ,  4.1, 61. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 50. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1. , 139. ,  81. ,   3.9,  62. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([61.,  1.,  1.,  2.,  1.,  1.,  2.,  2.,  2.,  2.,  1.,  2.,  2.,\n",
       "          1., 85., 58.,  4., 61.,  2.]),\n",
       "  1.0),\n",
       " (array([54. ,  1. ,  2. ,  2. ,  1. ,  2. ,  2. ,  1. ,  1. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  3.2, 85. , 28. ,  3.8, 61. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 56. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   1. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   2.9,  90. , 153. ,   4. ,  61. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 20. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           2. ,   1. ,   1. ,   2. ,   1. , 160. , 118. ,   2.9,  23. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([42. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  1. ,  2. ,\n",
       "          2. ,  2. ,  1.5, 85. , 40. ,  4. , 61. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 37. ,   1. ,   1. ,   2. ,   1. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   0.9,  85. , 231. ,   4.3,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([50.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  1.,  1.,  1.,  2.,  2.,\n",
       "          1., 85., 75.,  4., 72.,  2.]),\n",
       "  2.0),\n",
       " (array([ 34. ,   2. ,   2. ,   2. ,   1. ,   1. ,   1. ,   1. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   0.7,  70. ,  24. ,   4.1, 100. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([28.,  1.,  2.,  2.,  1.,  1.,  1.,  2.,  2.,  2.,  1.,  1.,  2.,\n",
       "          1., 85., 20.,  4., 61.,  2.]),\n",
       "  2.0),\n",
       " (array([ 50. ,   1. ,   2. ,   2. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           1. ,   2. ,   1. ,   1. ,   2.8, 155. ,  75. ,   2.4,  32. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([54. ,  1. ,  1. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          1. ,  2. ,  1.2, 85. , 92. ,  3.1, 66. ,  2. ]),\n",
       "  2.0),\n",
       " (array([57. ,  1. ,  1. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  2. ,  1. ,\n",
       "          1. ,  2. ,  4.6, 82. , 55. ,  3.3, 30. ,  2. ]),\n",
       "  1.0),\n",
       " (array([54. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1. , 85. , 30. ,  4.5,  0. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 31. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           1. ,   2. ,   2. ,   2. ,   8. ,  85. , 101. ,   2.2,  61. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 48. ,   1. ,   2. ,   2. ,   1. ,   1. ,   1. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   2. ,   2. , 158. , 278. ,   3.8,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 72. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1. , 115. ,  52. ,   3.4,  50. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 38. ,   1. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.4, 243. ,  49. ,   3.8,  90. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 25. ,   1. ,   2. ,   2. ,   1. ,   2. ,   2. ,   1. ,   1. ,\n",
       "           1. ,   1. ,   1. ,   1. ,   1.3, 181. , 181. ,   4.5,  57. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([51. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  1. ,  1. ,  2. ,  1. ,\n",
       "          2. ,  2. ,  0.8, 85. , 33. ,  4.5, 61. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 38. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   1. ,   1.6, 130. , 140. ,   3.5,  56. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 47. ,   1. ,   2. ,   2. ,   1. ,   1. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   1. ,   1. ,   1. ,   1. , 166. ,  30. ,   2.6,  31. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([45. ,  1. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,  2. ,\n",
       "          2. ,  2. ,  1.3, 85. , 44. ,  4.2, 85. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 36. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   1. ,   1. ,\n",
       "           2. ,   1. ,   2. ,   1. ,   1.7, 295. ,  60. ,   2.7,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 54. ,   1. ,   1. ,   2. ,   1. ,   1. ,   2. ,   2. ,   2. ,\n",
       "           1. ,   2. ,   1. ,   2. ,   3.9, 120. ,  28. ,   3.5,  43. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([51.,  1.,  2.,  2.,  1.,  2.,  2.,  2.,  1.,  1.,  1.,  2.,  1.,\n",
       "          1., 85., 20.,  3., 63.,  2.]),\n",
       "  2.0),\n",
       " (array([49. ,  1. ,  1. ,  2. ,  1. ,  1. ,  2. ,  2. ,  2. ,  1. ,  1. ,\n",
       "          2. ,  2. ,  1.4, 85. , 70. ,  3.5, 35. ,  2. ]),\n",
       "  1.0),\n",
       " (array([ 45. ,   1. ,   2. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           2. ,   1. ,   1. ,   2. ,   1.9,  85. , 114. ,   2.4,  61. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 31. ,   1. ,   1. ,   2. ,   1. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.2,  75. , 173. ,   4.2,  54. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 41. ,   1. ,   2. ,   2. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           1. ,   1. ,   2. ,   1. ,   4.2,  65. , 120. ,   3.4,  61. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 70. ,   1. ,   1. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   1.7, 109. , 528. ,   2.8,  35. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 20. ,   1. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.9,  89. , 152. ,   4. ,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 36. ,   1. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.6, 120. ,  30. ,   4. ,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([ 46. ,   1. ,   2. ,   2. ,   1. ,   1. ,   1. ,   2. ,   2. ,\n",
       "           2. ,   1. ,   1. ,   1. ,   7.6,  85. , 242. ,   3.3,  50. ,\n",
       "           2. ]),\n",
       "  1.0),\n",
       " (array([ 44. ,   1. ,   2. ,   2. ,   1. ,   2. ,   2. ,   2. ,   1. ,\n",
       "           2. ,   2. ,   2. ,   2. ,   0.9, 126. , 142. ,   4.3,  61. ,\n",
       "           2. ]),\n",
       "  2.0),\n",
       " (array([61. ,  1. ,  1. ,  2. ,  1. ,  1. ,  2. ,  1. ,  1. ,  2. ,  1. ,\n",
       "          2. ,  2. ,  0.8, 75. , 20. ,  4.1, 61. ,  2. ]),\n",
       "  2.0),\n",
       " (array([53. ,  2. ,  1. ,  2. ,  1. ,  2. ,  2. ,  2. ,  2. ,  1. ,  1. ,\n",
       "          2. ,  1. ,  1.5, 81. , 19. ,  4.1, 48. ,  2. ]),\n",
       "  2.0),\n",
       " (array([ 43. ,   1. ,   2. ,   2. ,   1. ,   2. ,   2. ,   2. ,   2. ,\n",
       "           1. ,   1. ,   1. ,   2. ,   1.2, 100. ,  19. ,   3.1,  42. ,\n",
       "           2. ]),\n",
       "  1.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188a59c-c387-4ad3-9101-417d1a5e703f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
